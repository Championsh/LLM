# ML and LLM for Code Analysis

This repository is devoted to using **Large Language Models** for solving Code Analysis tasks.

In this repository, you can find examples of:
- C++ functionality such as **file i/o**, **stream i/o**, **vectors**, **stacks**.
- Python functionality such as **itertools.product**, **copy.deepcopy**, **collections.Counter**, **file i/o**.

## Tested LLM Models
- Llama 2,
- Marcoroni-70B-v1,
- FashionGPT-70B-V1.1,
- Uni-TianYan,
- ORCA_LLaMA_70B_QLoRA,
- Falcon-40B,
- Falcon-180B,
- Starchat,
- Llama2-13B,
- Llama2-70B,
- Gigachat,
- YandexGPT,
- ChatGPT baseline,
- TheB.Ai,
- AutoGen (GPT based)

## Project Tree
```
├── 1_warning_explanation
│   └── ...
├── 2_test_translation
│   ├── prompt_1
│   │   └── ...
│   ├── prompt_2
│   │   └── ...
│   ├── prompt_3
│   │   └── ...
│   ├── prompt_4
│   │   └── ...
│   ├── prompt_5
│   │   └── ...
│   └── prompts
│       └── ...
├── 3_test_generation
│   └── tg_1_prompt.txt
├── 4_spec_generation
│   └── ...
├── 5_comment_generation
│   └── ...
├── apps
│   ├── hf_not_working.py
│   ├── llama_chat.py
│   ├── prompts
│   │   ├── sg_9_prompt.txt
│   │   ├── we-1-prompt.txt
│   │   └── we-3-prompt.txt
│   ├── requirements.txt
│   └── unused
│       └── ...
├── .gitignore
├── ReadMe
├── sg_rules
├── src
│   └── inference.py
└── test_generation_NotATask
    └── ...
```
